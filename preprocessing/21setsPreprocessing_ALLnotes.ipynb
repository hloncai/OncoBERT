{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import inflect\n",
    "from tqdm import tqdm\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pandas==1.3.2 in /usr/local/share/anaconda3/lib/python3.7/site-packages (1.3.2)\r\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from pandas==1.3.2) (2019.3)\r\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.3 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from pandas==1.3.2) (1.18.5)\r\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from pandas==1.3.2) (2.8.1)\r\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/share/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.3.2) (1.15.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training(experiment_number):\n",
    "    train_path = \"/data/users/linh/USF_Practicum/glioma/glioma_train_180\" + \"_\" + str(experiment_number)+\".pkl\"\n",
    "    data = pd.read_pickle(train_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "def text_replace(x):\n",
    "    y=re.sub('\\*', '', x)\n",
    "    y=re.sub('\\/\\/', '', y)\n",
    "    y=re.sub('\\\\\\\\', '', y)\n",
    "  #  y=re.sub(' \\*.*?\\* ','',x) #remove de-identified brackets\n",
    " #   y=re.sub('\\*.*?\\//*','',x) #remove de-identified brackets\n",
    "    y=re.sub('[0-9]+\\.  ','',y) #remove 1.  , 2.   since the segmenter segments based on this. preserve 1.2 \n",
    "    y=re.sub('dr\\.','doctor',y)\n",
    "    y=re.sub('m\\.d\\.','md',y)\n",
    "    y=re.sub('admission date:','',y)\n",
    "    y=re.sub('discharge date:','',y)\n",
    "    y=re.sub('--|__|==','',y)\n",
    "    y=re.sub(r\"\\b\\d+\\b\", lambda m: inflect.engine().number_to_words(m.group()), y) # '\\b \\b' means whole word only\n",
    "    return y\n",
    "\n",
    "def text_clean(df): \n",
    "    df_cleaned = df.copy()\n",
    "    df_cleaned['text']=df_cleaned['text'].fillna(' ')\n",
    "    df_cleaned['text']=df_cleaned['text'].str.replace('\\n',' ')\n",
    "    df_cleaned['text']=df_cleaned['text'].str.replace('\\r',' ')\n",
    "    df_cleaned['text']=df_cleaned['text'].apply(str.strip)\n",
    "    df_cleaned['text']=df_cleaned['text'].str.lower()\n",
    "    df_cleaned['text']=df_cleaned['text'].apply(lambda x: text_replace(x))\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "def trunk510(df):\n",
    "    want = pd.DataFrame({'ID':[], 'Token_trunc':[]})\n",
    "    for i in range(len(df)):\n",
    "        length = df['len'][i]\n",
    "        n = int(np.ceil(length/400))\n",
    "        for j in range(n):\n",
    "            tok = df['Token'][i][j*400: j*400+510]\n",
    "            want = want.append({\n",
    "                'Token_trunc': tok,\n",
    "                'ID': df['ptId'][i]}, ignore_index=True)\n",
    "    return want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [41:56<00:00, 119.85s/it]\n"
     ]
    }
   ],
   "source": [
    "for experiment_number in tqdm(range(21)):\n",
    "    data = read_training(experiment_number)\n",
    "    df = pd.DataFrame(data)\n",
    "    df['ptId'] = df.index\n",
    "    df_cleaned = text_clean(df)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    df_cleaned['Token'] = df_cleaned['text'].apply(lambda x: tokenizer.tokenize(x))\n",
    "    df_cleaned['len'] = df_cleaned['Token'].apply(lambda x: len(x))\n",
    "    df_trunked = trunk510(df_cleaned) # no label needed\n",
    "    df_trunked.to_pickle('/data/users/linh/USF_Practicum/glioma_tokenized/glioma_train_180_' + str(experiment_number) + '_tokens' + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Token_trunc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[b, \", thank, -, you, for, referring, to, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[mouth, daily, ., col, ##chi, ##cine, zero, .,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[:, negative, for, chest, pain, ,, pal, ##pit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[with, g, ##lio, ##bla, ##sto, ##ma, ., there,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[or, loss, of, consciousness, ., he, does, thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21633</th>\n",
       "      <td>377</td>\n",
       "      <td>[tesla, ., contrast, media, :, intra, ##ven, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21634</th>\n",
       "      <td>377</td>\n",
       "      <td>[., maintenance, phase, :, administered, at, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21635</th>\n",
       "      <td>377</td>\n",
       "      <td>[all, patients, receiving, con, ##com, ##itan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21636</th>\n",
       "      <td>377</td>\n",
       "      <td>[radio, ##therapy, given, at, /, day, five, da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21637</th>\n",
       "      <td>377</td>\n",
       "      <td>[prop, ##hyl, ##ax, ##is, against, p, ##ne, ##...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21638 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                        Token_trunc\n",
       "0        0  [b, \", thank, -, you, for, referring, to, the,...\n",
       "1        0  [mouth, daily, ., col, ##chi, ##cine, zero, .,...\n",
       "2        0  [:, negative, for, chest, pain, ,, pal, ##pit,...\n",
       "3        0  [with, g, ##lio, ##bla, ##sto, ##ma, ., there,...\n",
       "4        0  [or, loss, of, consciousness, ., he, does, thi...\n",
       "...    ...                                                ...\n",
       "21633  377  [tesla, ., contrast, media, :, intra, ##ven, #...\n",
       "21634  377  [., maintenance, phase, :, administered, at, o...\n",
       "21635  377  [all, patients, receiving, con, ##com, ##itan,...\n",
       "21636  377  [radio, ##therapy, given, at, /, day, five, da...\n",
       "21637  377  [prop, ##hyl, ##ax, ##is, against, p, ##ne, ##...\n",
       "\n",
       "[21638 rows x 2 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_v = pd.read_pickle('/data/users/linh/USF_Practicum/glioma_tokenized/glioma_train_180_8_tokens.pkl')\n",
    "df_train_v['ID'] = df_train_v['ID'].apply(lambda x: int(x))\n",
    "df_train_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_testing(experiment_number):\n",
    "    test_path = \"/data/users/linh/USF_Practicum/glioma/glioma_test_180\" + \"_\" + str(experiment_number)+\".pkl\"\n",
    "    data_test = pd.read_pickle(test_path)\n",
    "    return data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [10:41<00:00, 30.55s/it]\n"
     ]
    }
   ],
   "source": [
    "for experiment_number in tqdm(range(21)):\n",
    "    data_test = read_testing(experiment_number)\n",
    "    df_test = pd.DataFrame(data_test)\n",
    "    df_test['ptId'] = df_test.index\n",
    "    df_test_cleaned = text_clean(df_test)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    df_test_cleaned['Token'] = df_test_cleaned['text'].apply(lambda x: tokenizer.tokenize(x))\n",
    "    df_test_cleaned['len'] = df_test_cleaned['Token'].apply(lambda x: len(x))\n",
    "    df_test_trunked = trunk510(df_test_cleaned) # no label needed\n",
    "    df_test_trunked.to_pickle('/data/users/linh/USF_Practicum/glioma_tokenized/glioma_test_180_' + str(experiment_number) + '_tokens' + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Token_trunc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[b, \", thank, -, you, for, referring, to, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[mouth, daily, ., col, ##chi, ##cine, zero, .,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[:, negative, for, chest, pain, ,, pal, ##pit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[with, g, ##lio, ##bla, ##sto, ##ma, ., there,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[or, loss, of, consciousness, ., he, does, thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6204</th>\n",
       "      <td>96</td>\n",
       "      <td>[tesla, ., contrast, media, :, intra, ##ven, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6205</th>\n",
       "      <td>96</td>\n",
       "      <td>[., maintenance, phase, :, administered, at, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6206</th>\n",
       "      <td>96</td>\n",
       "      <td>[all, patients, receiving, con, ##com, ##itan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6207</th>\n",
       "      <td>96</td>\n",
       "      <td>[radio, ##therapy, given, at, /, day, five, da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6208</th>\n",
       "      <td>96</td>\n",
       "      <td>[prop, ##hyl, ##ax, ##is, against, p, ##ne, ##...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6209 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                        Token_trunc\n",
       "0      0  [b, \", thank, -, you, for, referring, to, the,...\n",
       "1      0  [mouth, daily, ., col, ##chi, ##cine, zero, .,...\n",
       "2      0  [:, negative, for, chest, pain, ,, pal, ##pit,...\n",
       "3      0  [with, g, ##lio, ##bla, ##sto, ##ma, ., there,...\n",
       "4      0  [or, loss, of, consciousness, ., he, does, thi...\n",
       "...   ..                                                ...\n",
       "6204  96  [tesla, ., contrast, media, :, intra, ##ven, #...\n",
       "6205  96  [., maintenance, phase, :, administered, at, o...\n",
       "6206  96  [all, patients, receiving, con, ##com, ##itan,...\n",
       "6207  96  [radio, ##therapy, given, at, /, day, five, da...\n",
       "6208  96  [prop, ##hyl, ##ax, ##is, against, p, ##ne, ##...\n",
       "\n",
       "[6209 rows x 2 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_v = pd.read_pickle('/data/users/linh/USF_Practicum/glioma_tokenized/glioma_test_180_5_tokens.pkl')\n",
    "df_test_v['ID'] = df_test_v['ID'].apply(lambda x: int(x))\n",
    "df_test_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
